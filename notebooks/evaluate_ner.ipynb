{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import argparse\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "print(load_dotenv(find_dotenv(\".env\")))\n",
    "\n",
    "def split_sentence_with_indices(text):\n",
    "    pattern = r'''\n",
    "        (?:\n",
    "            \\d+[.,]?\\d*\\s*[%$€]?\n",
    "        )                                     # Numbers with optional decimal/currency\n",
    "        |\n",
    "        [A-Za-zÀ-ÖØ-öø-ÿ0-9]+(?:-[A-Za-z0-9]+)*  # Words with optional hyphens (e.g., anti-TNF)\n",
    "        |\n",
    "        [()\\[\\]{}]                             # Parentheses and brackets\n",
    "        |\n",
    "        [^\\w\\s]                                # Other single punctuation marks\n",
    "    '''\n",
    "    return list(re.finditer(pattern, text, flags=re.VERBOSE))\n",
    "\n",
    "\n",
    "\n",
    "def write_annotations_to_file(data, file_path):\n",
    "    \"\"\"\n",
    "    Writes annotation data to a TSV file.\n",
    "\n",
    "    Parameters:\n",
    "        data (list of dict): Each dict should have keys:\n",
    "            'filename', 'ann_id', 'label', 'start_span', 'end_span', 'text'\n",
    "        file_path (str): Path to the output file\n",
    "    \"\"\"\n",
    "    header = ['filename', 'ann_id', 'label', 'start_span', 'end_span', 'text']\n",
    "\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        # Write the header\n",
    "        f.write('\\t'.join(header) + '\\n')\n",
    "        # Write each row\n",
    "        for entry in data:\n",
    "            row = [str(entry[key]) for key in header]\n",
    "            f.write('\\t'.join(row) + '\\n')\n",
    "\n",
    "\n",
    "def load_tsv_to_dataframe(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads a TSV file with specific columns into a pandas DataFrame.\n",
    "\n",
    "    Expected columns:\n",
    "        filename, label, start_span, end_span, text, note\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the TSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the TSV data.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        sep='\\t',\n",
    "        dtype={\n",
    "            \"filename\": str,\n",
    "            \"label\": str,\n",
    "            \"start_span\": int,\n",
    "            \"end_span\": int,\n",
    "            \"text\": str,\n",
    "            \"note\": str\n",
    "        },\n",
    "        keep_default_na=False  # Prevents empty strings being converted to NaN\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "class PredictionNER:\n",
    "    def __init__(self, model_checkpoint, revision) -> None:\n",
    "        MAX_LENGTH = 450\n",
    "        OVERLAPPING_LEN = 10 \n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_checkpoint, revision=revision, is_split_into_words=True, truncation=False\n",
    "        )\n",
    "        self.model = AutoModelForTokenClassification.from_pretrained(\n",
    "            model_checkpoint, revision=revision\n",
    "        )\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "            encoding_name='o200k_base',\n",
    "            separators=[\"\\n\\n\\n\", \"\\n\\n\", \"\\n\", \".\", \",\", \" \", \"\"],\n",
    "            keep_separator=False,\n",
    "            chunk_size=MAX_LENGTH,\n",
    "            chunk_overlap=OVERLAPPING_LEN,\n",
    "        )\n",
    "\n",
    "        ner_labels = list(self.model.config.id2label.values())\n",
    "        self.base_entity_types = sorted(\n",
    "            set(label[2:] for label in ner_labels if label != \"O\")\n",
    "        )\n",
    "\n",
    "\n",
    "    def split_text_with_indices(self, text):\n",
    "        offset = 0\n",
    "        for doc in self.text_splitter.split_text(text):\n",
    "            # Search for doc within the remaining text\n",
    "            start_idx = text.find(doc, offset)\n",
    "            if start_idx == -1:\n",
    "                continue  # should not happen, but skip just in case\n",
    "            end_idx = start_idx + len(doc)\n",
    "            offset = end_idx  # move search window forward\n",
    "            yield doc, start_idx, end_idx\n",
    "\n",
    "    def predict_text(self, text: str, confidence_threshold: float = 0.7):\n",
    "        # 1. Split text into words and punctuation using regex\n",
    "        text_matches = split_sentence_with_indices(text)  # list(re.finditer(r'([0-9A-Za-zÀ-ÖØ-öø-ÿ]+|[^0-9A-Za-zÀ-ÖØ-öø-ÿ])', text))\n",
    "\n",
    "        # 2. Strip and filter out empty or whitespace-only tokens\n",
    "        text_words = [m.group().strip() for m in text_matches if m.group().strip()]\n",
    "\n",
    "        if not text_words:\n",
    "            return []  # return early if nothing valid\n",
    "\n",
    "        # 3. Tokenize with word alignment\n",
    "        inputs = self.tokenizer(\n",
    "            text_words, \n",
    "            return_tensors=\"pt\", \n",
    "            is_split_into_words=True,\n",
    "            truncation=False\n",
    "        )\n",
    "        word_ids = inputs.word_ids()\n",
    "\n",
    "        # 4. Predict\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(**inputs).logits\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=2)[0]\n",
    "\n",
    "        # 5. Map predictions back to original stripped words\n",
    "        results = []\n",
    "        seen = set()\n",
    "        non_empty_matches = [m for m in text_matches if m.group().strip()]\n",
    "\n",
    "        for i, word_idx in enumerate(word_ids):\n",
    "            if word_idx is None or word_idx in seen:\n",
    "                continue\n",
    "            seen.add(word_idx)\n",
    "\n",
    "            word = text_words[word_idx]\n",
    "            tag_id = predictions[i].item()\n",
    "            tag = self.model.config.id2label[tag_id]\n",
    "            score = probs[0, i, tag_id].item()\n",
    "            start = non_empty_matches[word_idx].start()\n",
    "            end = non_empty_matches[word_idx].end()\n",
    "\n",
    "            # Apply the confidence threshold filter\n",
    "            if score < confidence_threshold:\n",
    "                tag = \"O\"  # Assign \"O\" tag if confidence is below threshold\n",
    "                score = 0.0  # Set score to 0 for \"O\" tag\n",
    "\n",
    "            results.append({\n",
    "                'word': word,\n",
    "                'tag': tag,\n",
    "                'start': start,\n",
    "                'end': end,\n",
    "                'score': score\n",
    "            })\n",
    "\n",
    "        return results\n",
    "\n",
    "    def aggregate_entities(self, tagged_tokens, original_text, confidence_threshold=0.3):\n",
    "        # Step 1: Preprocess tags based on the two rules\n",
    "        corrected_tokens = tagged_tokens.copy()\n",
    "\n",
    "        # Rule 1: Fix \"O\" between \"B-\" and \"I-\" of the same type\n",
    "        for i in range(1, len(tagged_tokens) - 1):\n",
    "            prev_tag = tagged_tokens[i - 1][\"tag\"]\n",
    "            curr_tag = tagged_tokens[i][\"tag\"]\n",
    "            next_tag = tagged_tokens[i + 1][\"tag\"]\n",
    "\n",
    "            if (\n",
    "                curr_tag == \"O\" and\n",
    "                prev_tag.startswith(\"B-\") and\n",
    "                next_tag.startswith(\"I-\")\n",
    "            ):\n",
    "                prev_type = prev_tag[2:]\n",
    "                next_type = next_tag[2:]\n",
    "                if prev_type == next_type:\n",
    "                    corrected_tokens[i][\"tag\"] = \"I-\" + prev_type\n",
    "\n",
    "        # Rule 2: Convert isolated or starting I- to B-\n",
    "        last_tag_type = None\n",
    "        for i in range(len(corrected_tokens)):\n",
    "            tag = corrected_tokens[i][\"tag\"]\n",
    "            if tag.startswith(\"I-\"):\n",
    "                tag_type = tag[2:]\n",
    "                if last_tag_type != tag_type:\n",
    "                    corrected_tokens[i][\"tag\"] = \"B-\" + tag_type\n",
    "                    last_tag_type = tag_type\n",
    "                else:\n",
    "                    last_tag_type = tag_type\n",
    "            elif tag.startswith(\"B-\"):\n",
    "                last_tag_type = tag[2:]\n",
    "            else:\n",
    "                last_tag_type = None\n",
    "\n",
    "        # Step 2: Apply original aggregation logic\n",
    "        entities = []\n",
    "        current_entity = None\n",
    "\n",
    "        for item in corrected_tokens:\n",
    "            tag = item[\"tag\"]\n",
    "            start = item[\"start\"]\n",
    "            end = item[\"end\"]\n",
    "            score = item[\"score\"]\n",
    "\n",
    "            if tag.startswith(\"B-\"):\n",
    "                if current_entity:\n",
    "                    if all(s >= confidence_threshold for s in current_entity[\"scores\"]):\n",
    "                        current_entity[\"text\"] = original_text[current_entity[\"start\"]:current_entity[\"end\"]]\n",
    "                        current_entity[\"score\"] = sum(current_entity[\"scores\"]) / len(current_entity[\"scores\"])\n",
    "                        del current_entity[\"scores\"]\n",
    "                        entities.append(current_entity)\n",
    "                    current_entity = None\n",
    "                tag_type = tag[2:]\n",
    "                current_entity = {\n",
    "                    \"start\": start,\n",
    "                    \"end\": end,\n",
    "                    \"tag\": tag_type,\n",
    "                    \"scores\": [score]\n",
    "                }\n",
    "\n",
    "            elif tag.startswith(\"I-\"):\n",
    "                tag_type = tag[2:]\n",
    "                if current_entity and current_entity[\"tag\"] == tag_type:\n",
    "                    current_entity[\"end\"] = end\n",
    "                    current_entity[\"scores\"].append(score)\n",
    "                else:\n",
    "                    current_entity = {\n",
    "                        \"start\": start,\n",
    "                        \"end\": end,\n",
    "                        \"tag\": tag_type,\n",
    "                        \"scores\": [score]\n",
    "                    }\n",
    "\n",
    "            else:  # \"O\"\n",
    "                if current_entity:\n",
    "                    if all(s >= confidence_threshold for s in current_entity[\"scores\"]):\n",
    "                        current_entity[\"text\"] = original_text[current_entity[\"start\"]:current_entity[\"end\"]]\n",
    "                        current_entity[\"score\"] = sum(current_entity[\"scores\"]) / len(current_entity[\"scores\"])\n",
    "                        del current_entity[\"scores\"]\n",
    "                        entities.append(current_entity)\n",
    "                    current_entity = None\n",
    "\n",
    "        if current_entity:\n",
    "            if all(s >= confidence_threshold for s in current_entity[\"scores\"]):\n",
    "                current_entity[\"text\"] = original_text[current_entity[\"start\"]:current_entity[\"end\"]]\n",
    "                current_entity[\"score\"] = sum(current_entity[\"scores\"]) / len(current_entity[\"scores\"])\n",
    "                del current_entity[\"scores\"]\n",
    "                entities.append(current_entity)\n",
    "\n",
    "        return entities\n",
    "\n",
    "\n",
    "    def do_prediction(self, text, confidence_threshold=0.6):\n",
    "        final_prediction = []\n",
    "        for sub_text, sub_text_start, sub_text_end in self.split_text_with_indices(text):\n",
    "            tokens = self.predict_text(text=sub_text, confidence_threshold=confidence_threshold)\n",
    "            predictions = self.aggregate_entities(tokens, sub_text, confidence_threshold=confidence_threshold)\n",
    "\n",
    "\n",
    "            for pred in predictions:\n",
    "                pred[\"start\"] += sub_text_start\n",
    "                pred[\"end\"] += sub_text_start\n",
    "                final_prediction.append(pred)\n",
    "\n",
    "        final_prediction_dict = {\n",
    "            lab: [p for p in final_prediction if p[\"tag\"] == lab]\n",
    "            for lab in self.base_entity_types\n",
    "        }\n",
    "        merged_predictions = []\n",
    "        for label in self.base_entity_types:\n",
    "            merged_predictions.extend(final_prediction_dict[label])\n",
    "        return merged_predictions\n",
    "\n",
    "\n",
    "def evaluate(model_checkpoint, revision, root_path, lang, cat):\n",
    "\n",
    "    ner = PredictionNER(model_checkpoint=model_checkpoint, revision=revision)\n",
    "\n",
    "    # conver the predictions to ann format\n",
    "    tsv_file_path_test = os.path.join(root_path,  f\"test_cardioccc_{lang}_{cat}.tsv\")\n",
    "    test_files_root =  os.path.join(root_path, \"txt\")\n",
    "\n",
    "    test_df = load_tsv_to_dataframe(tsv_file_path_test)\n",
    "    prd_ann = []\n",
    "\n",
    "    for fn in tqdm(test_df['filename'].unique()):\n",
    "\n",
    "        with open(os.path.join(test_files_root, fn+\".txt\"), 'r', encoding='utf-8') as f:\n",
    "            document_text = f.read()\n",
    "            prds = ner.do_prediction(document_text, confidence_threshold=0.35)\n",
    "            for prd in prds:\n",
    "                prd_ann.append({\n",
    "                    \"filename\": fn,\n",
    "                    \"label\": prd[\"tag\"],\n",
    "                    \"ann_id\": \"NA\",\n",
    "                    \"start_span\": prd[\"start\"],\n",
    "                    \"end_span\": prd[\"end\"],\n",
    "                    \"text\": prd[\"text\"],\n",
    "                })\n",
    "\n",
    "    output_tsv_path = os.path.join(root_path, f\"pre_{model_checkpoint.split('/')[1]}_{revision}.tsv\")\n",
    "    write_annotations_to_file(prd_ann, output_tsv_path)\n",
    "    print(f\"output_tsv_path {output_tsv_path}\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"DT4H-IE/CardioBERTa.en_EN_MED\"\n",
    "revision = \"2025-05-07_19-08-13-d46774ee\"\n",
    "root = \"dataset/English\" \n",
    "cat = \"med\"\n",
    "lang = \"en\"\n",
    "\n",
    "evaluate(model_checkpoint, revision, root, lang, cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To load pre-trained model training configs:\n",
    "\n",
    "# arg_path  = r\"./trained_models/model_bert-base-spanish-wwm-cased_es_med_30042025_06bc94a6/training_args.bin\"\n",
    "\n",
    "# import torch\n",
    "\n",
    "# # Load the full object (not just weights)\n",
    "# training_args = torch.load(arg_path, weights_only=False)\n",
    "\n",
    "# print(training_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
